import json
import pandas as pd
import glob
import os
from datetime import datetime

def process_medical_recent_news():
    """
    medical_recent_news JSON íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ê³ ìœ í•œ ë‰´ìŠ¤ë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    print("=" * 60)
    print("MEDICAL RECENT NEWS ì²˜ë¦¬ ì‹œì‘")
    print("=" * 60)
    
    # crawler_result ë””ë ‰í† ë¦¬ì—ì„œ medical_recent_newsê°€ í¬í•¨ëœ JSON íŒŒì¼ë“¤ ì°¾ê¸°
    json_files = glob.glob('/home/son/SKN12-FINAL-AIRFLOW/crawler_result/medical_recent_news_*.json')
    
    if not json_files:
        print("medical_recent_news JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    if len(json_files) < 2:
        print("ë¹„êµí•  íŒŒì¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ 2ê°œ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return []
    
    # íŒŒì¼ë“¤ì„ ìƒì„± ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ê°€ì¥ ìµœì‹  íŒŒì¼ì„ ì°¾ê¸° ìœ„í•´)
    json_files.sort(key=os.path.getctime)
    latest_file = json_files[-1]  # ê°€ì¥ ìµœì‹  íŒŒì¼
    other_files = json_files[:-1]  # ë‚˜ë¨¸ì§€ íŒŒì¼ë“¤
    
    print(f"ê°€ì¥ ìµœì‹  íŒŒì¼: {os.path.basename(latest_file)}")
    print(f"ë¹„êµí•  ë‹¤ë¥¸ íŒŒì¼ë“¤: {len(other_files)}ê°œ")
    
    # 1. ìµœì‹  íŒŒì¼ ì½ê¸°
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            latest_data = json.load(f)
    except Exception as e:
        print(f"ìµœì‹  íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
        return []
    
    # JSON êµ¬ì¡° í™•ì¸ ë° news_list ì¶”ì¶œ
    if isinstance(latest_data, dict) and 'news_list' in latest_data:
        latest_news_list = latest_data['news_list']
    else:
        print("ìµœì‹  íŒŒì¼ì´ ì˜ˆìƒëœ êµ¬ì¡°ê°€ ì•„ë‹™ë‹ˆë‹¤. (news_list í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ)")
        return []
    
    print(f"ìµœì‹  íŒŒì¼ì—ì„œ {len(latest_news_list)}ê°œ ê¸°ì‚¬ ë°œê²¬")
    
    # 2. ë‹¤ë¥¸ ëª¨ë“  íŒŒì¼ë“¤ì—ì„œ URLê³¼ title ì¡°í•© ìˆ˜ì§‘
    existing_url_title_pairs = set()
    
    for file_path in other_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, dict) and 'news_list' in data:
                news_list = data['news_list']
                for item in news_list:
                    url = item.get('url', '').strip()
                    title = item.get('title', '').strip()
                    if url and title:
                        existing_url_title_pairs.add((url, title))
        except Exception:
            continue
    
    # 3. ìµœì‹  íŒŒì¼ì—ì„œ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ê¸°ì‚¬ë§Œ í•„í„°ë§
    unique_articles = []
    duplicate_count = 0
    
    for item in latest_news_list:
        url = item.get('url', '').strip()
        title = item.get('title', '').strip()
        
        if url and title:
            current_pair = (url, title)
            
            if current_pair not in existing_url_title_pairs:
                processed_item = {
                    'ì œëª©': title,
                    'url': url,
                    'ì–¸ë¡ ì‚¬': 'yakup.com',  # ê³ ì •ê°’
                    'ì—…ë¡œë“œ_ë‚ ì§œ': item.get('date', ''),
                    'íƒ€ì…': 'medical news',  # ê³ ì •ê°’
                    'ìš”ì•½': item.get('summary', '')
                }
                unique_articles.append(processed_item)
            else:
                duplicate_count += 1
        else:
            duplicate_count += 1
    
    print(f"Recent News ì¤‘ë³µ ì œê±° ê²°ê³¼:")
    print(f"  - ìµœì‹  íŒŒì¼ ì´ ê¸°ì‚¬: {len(latest_news_list)}ê°œ")
    print(f"  - ì¤‘ë³µëœ ê¸°ì‚¬: {duplicate_count}ê°œ")
    print(f"  - ê³ ìœ í•œ ê¸°ì‚¬: {len(unique_articles)}ê°œ")
    
    return unique_articles

def process_medical_top_trending_news():
    """
    medical_top_trending_news JSON íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ê³ ìœ í•œ ë‰´ìŠ¤ë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    print("=" * 60)
    print("MEDICAL TOP TRENDING NEWS ì²˜ë¦¬ ì‹œì‘")
    print("=" * 60)
    
    # crawler_result ë””ë ‰í† ë¦¬ì—ì„œ medical_top_trending_newsê°€ í¬í•¨ëœ JSON íŒŒì¼ë“¤ ì°¾ê¸°
    json_files = glob.glob('/home/son/SKN12-FINAL-AIRFLOW/crawler_result/medical_top_trending_news_*.json')
    
    if not json_files:
        print("medical_top_trending_news JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    if len(json_files) < 2:
        print("ë¹„êµí•  íŒŒì¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ 2ê°œ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return []
    
    # íŒŒì¼ë“¤ì„ ìƒì„± ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ê°€ì¥ ìµœì‹  íŒŒì¼ì„ ì°¾ê¸° ìœ„í•´)
    json_files.sort(key=os.path.getctime)
    latest_file = json_files[-1]  # ê°€ì¥ ìµœì‹  íŒŒì¼
    other_files = json_files[:-1]  # ë‚˜ë¨¸ì§€ íŒŒì¼ë“¤
    
    print(f"ê°€ì¥ ìµœì‹  íŒŒì¼: {os.path.basename(latest_file)}")
    print(f"ë¹„êµí•  ë‹¤ë¥¸ íŒŒì¼ë“¤: {len(other_files)}ê°œ")
    
    # 1. ìµœì‹  íŒŒì¼ ì½ê¸°
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            latest_data = json.load(f)
    except Exception as e:
        print(f"ìµœì‹  íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
        return []
    
    # JSON êµ¬ì¡° í™•ì¸ ë° news_list ì¶”ì¶œ
    if isinstance(latest_data, dict) and 'news_list' in latest_data:
        latest_news_list = latest_data['news_list']
    else:
        print("ìµœì‹  íŒŒì¼ì´ ì˜ˆìƒëœ êµ¬ì¡°ê°€ ì•„ë‹™ë‹ˆë‹¤. (news_list í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ)")
        return []
    
    print(f"ìµœì‹  íŒŒì¼ì—ì„œ {len(latest_news_list)}ê°œ ê¸°ì‚¬ ë°œê²¬")
    
    # 2. ë‹¤ë¥¸ ëª¨ë“  íŒŒì¼ë“¤ì—ì„œ URLê³¼ title ì¡°í•© ìˆ˜ì§‘
    existing_url_title_pairs = set()
    
    for file_path in other_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, dict) and 'news_list' in data:
                news_list = data['news_list']
                for item in news_list:
                    url = item.get('url', '').strip()
                    title = item.get('title', '').strip()
                    if url and title:
                        existing_url_title_pairs.add((url, title))
        except Exception:
            continue
    
    # 3. ìµœì‹  íŒŒì¼ì—ì„œ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ê¸°ì‚¬ë§Œ í•„í„°ë§
    unique_articles = []
    duplicate_count = 0
    
    for item in latest_news_list:
        url = item.get('url', '').strip()
        title = item.get('title', '').strip()
        
        if url and title:
            current_pair = (url, title)
            
            if current_pair not in existing_url_title_pairs:
                processed_item = {
                    'ì œëª©': title,
                    'url': url,
                    'ì–¸ë¡ ì‚¬': item.get('source', ''),  # JSONì˜ source ê°’
                    'ì—…ë¡œë“œ_ë‚ ì§œ': item.get('pub_time', ''),  # JSONì˜ pub_time ê°’
                    'íƒ€ì…': item.get('type', ''),  # JSONì˜ type ê°’
                    'ìš”ì•½': item.get('summary', '')
                }
                unique_articles.append(processed_item)
            else:
                duplicate_count += 1
        else:
            duplicate_count += 1
    
    print(f"Top Trending News ì¤‘ë³µ ì œê±° ê²°ê³¼:")
    print(f"  - ìµœì‹  íŒŒì¼ ì´ ê¸°ì‚¬: {len(latest_news_list)}ê°œ")
    print(f"  - ì¤‘ë³µëœ ê¸°ì‚¬: {duplicate_count}ê°œ")
    print(f"  - ê³ ìœ í•œ ê¸°ì‚¬: {len(unique_articles)}ê°œ")
    
    return unique_articles

def preprocess_medical_news():
    """
    medical_recent_newsì™€ medical_top_trending_newsë¥¼ ëª¨ë‘ ì²˜ë¦¬í•˜ì—¬ 
    í•˜ë‚˜ì˜ Excel íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    print("ğŸ¥ MEDICAL NEWS ì „ì²˜ë¦¬ ì‹œì‘")
    print("=" * 80)
    
    # 1. Recent News ì²˜ë¦¬
    recent_articles = process_medical_recent_news()
    
    # 2. Top Trending News ì²˜ë¦¬  
    trending_articles = process_medical_top_trending_news()
    
    # 3. ë‘ ê²°ê³¼ í•©ì¹˜ê¸°
    all_articles = recent_articles + trending_articles
    
    print("=" * 60)
    print("ì „ì²´ ê²°ê³¼ í•©ê³„")
    print("=" * 60)
    print(f"Recent News ê³ ìœ  ê¸°ì‚¬: {len(recent_articles)}ê°œ")
    print(f"Top Trending News ê³ ìœ  ê¸°ì‚¬: {len(trending_articles)}ê°œ")
    print(f"ì „ì²´ ê³ ìœ  ê¸°ì‚¬: {len(all_articles)}ê°œ")
    
    if not all_articles:
        print("ì²˜ë¦¬í•  ê³ ìœ í•œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. Excel íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    
    # 4. DataFrame ìƒì„±
    df = pd.DataFrame(all_articles)
    
    # ë¹ˆ URL ì œê±° (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)
    df = df[df['url'].str.strip() != '']
    
    print(f"ìµœì¢… ì²˜ë¦¬ëœ ê¸°ì‚¬: {len(df)}ê°œ")
    
    # 5. Excel íŒŒì¼ë¡œ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f'/home/son/SKN12-FINAL-AIRFLOW/crawler_result/medical_news_unique_{timestamp}.xlsx'
    
    df.to_excel(output_file, index=False, engine='openpyxl')
    print(f"\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ. ì €ì¥ëœ íŒŒì¼: {output_file}")
    
    # í†µê³„ ì •ë³´ ì¶œë ¥
    if len(df) > 0:
        print("\nğŸ“Š í†µí•© ê¸°ì‚¬ í†µê³„:")
        
        # ì–¸ë¡ ì‚¬ë³„ í†µê³„
        if 'ì–¸ë¡ ì‚¬' in df.columns:
            press_counts = df['ì–¸ë¡ ì‚¬'].value_counts()
            print("\nì–¸ë¡ ì‚¬ë³„ ê¸°ì‚¬ ìˆ˜:")
            for press, count in press_counts.items():
                print(f"  {press}: {count}ê°œ")
        
        # íƒ€ì…ë³„ í†µê³„  
        if 'íƒ€ì…' in df.columns:
            type_counts = df['íƒ€ì…'].value_counts()
            print("\níƒ€ì…ë³„ ê¸°ì‚¬ ìˆ˜:")
            for news_type, count in type_counts.items():
                print(f"  {news_type}: {count}ê°œ")
        
        # ë‚ ì§œë³„ í†µê³„
        if 'ì—…ë¡œë“œ_ë‚ ì§œ' in df.columns:
            date_counts = df['ì—…ë¡œë“œ_ë‚ ì§œ'].value_counts()
            print("\në‚ ì§œë³„ ê¸°ì‚¬ ìˆ˜ (ìƒìœ„ 5ê°œ):")
            for date, count in date_counts.head(5).items():
                print(f"  {date}: {count}ê°œ")
    
    return df

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
def preprocess_medical_recent_news():
    """í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ (ê¸°ì¡´ í•¨ìˆ˜ëª…)"""
    return preprocess_medical_news()

if __name__ == "__main__":
    preprocess_medical_news()