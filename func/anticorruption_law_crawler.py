#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import time
from datetime import datetime
from bs4 import BeautifulSoup
import os
import tempfile
import uuid
import random
import subprocess
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

def setup_chrome_driver_ubuntu():
    """ìš°ë¶„íˆ¬ í™˜ê²½ì— ìµœì í™”ëœ Chrome ë“œë¼ì´ë²„ ì„¤ì •"""
    
    # ê¸°ì¡´ Chrome í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
    try:
        subprocess.run(['pkill', '-f', 'chrome'], capture_output=True, timeout=5)
        subprocess.run(['pkill', '-f', 'chromedriver'], capture_output=True, timeout=5)
        time.sleep(2)
        print("ğŸ§¹ ê¸°ì¡´ Chrome/ChromeDriver í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    except:
        pass
    
    try:
        chrome_options = Options()
        
        # Docker í™˜ê²½ì—ì„œëŠ” ë°˜ë“œì‹œ headless ëª¨ë“œ í•„ìš”
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-software-rasterizer')
        chrome_options.add_argument('--window-size=1280,720')
        
        # ì„¸ì…˜ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•œ í•µì‹¬ ì˜µì…˜ë“¤
        chrome_options.add_argument('--disable-web-security')
        chrome_options.add_argument('--disable-features=VizDisplayCompositor,ChromeWhatsNewUI')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-default-apps')
        chrome_options.add_argument('--disable-sync')
        chrome_options.add_argument('--disable-background-timer-throttling')
        chrome_options.add_argument('--disable-renderer-backgrounding')
        chrome_options.add_argument('--disable-backgrounding-occluded-windows')
        chrome_options.add_argument('--disable-client-side-phishing-detection')
        chrome_options.add_argument('--disable-component-extensions-with-background-pages')
        chrome_options.add_argument('--disable-ipc-flooding-protection')
        chrome_options.add_argument('--no-default-browser-check')
        chrome_options.add_argument('--no-first-run')
        chrome_options.add_argument('--disable-background-networking')
        chrome_options.add_argument('--disable-images')  # ì´ë¯¸ì§€ ë¡œë”© ë¹„í™œì„±í™”ë¡œ ì†ë„ í–¥ìƒ
        
        # ê³ ìœ  ì„¸ì…˜ì„ ìœ„í•œ ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = tempfile.mkdtemp(prefix=f'chrome_session_{uuid.uuid4().hex[:8]}_')
        chrome_options.add_argument(f'--user-data-dir={temp_dir}')
        
        # ê³ ìœ  ë””ë²„ê¹… í¬íŠ¸ ì„¤ì •
        debug_port = random.randint(9500, 9999)
        chrome_options.add_argument(f'--remote-debugging-port={debug_port}')
        
        # ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ìµœì í™”
        chrome_options.add_argument('--memory-pressure-off')
        chrome_options.add_argument('--max_old_space_size=2048')
        chrome_options.add_argument('--aggressive-cache-discard')
        
        # User Agent ì„¤ì •
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36')
        
        # ìë™í™” ê°ì§€ ë°©ì§€
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        print(f"ğŸ”§ ì„ì‹œ ì„¸ì…˜ ë””ë ‰í† ë¦¬: {temp_dir}")
        print(f"ğŸ”§ ë””ë²„ê¹… í¬íŠ¸: {debug_port}")
        
        # Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” - ëª…ì‹œì  ChromeDriver ê²½ë¡œ ì‚¬ìš©
        try:
            # ChromeDriver ê²½ë¡œ ì„¤ì • (Docker ìš°ì„ , ë¡œì»¬ ëŒ€ì•ˆ)
            chromedriver_paths = [
                '/usr/local/bin/chromedriver',  # Docker í™˜ê²½
                '/home/son/chromedriver'        # ë¡œì»¬ í™˜ê²½
            ]
            
            service = None
            for path in chromedriver_paths:
                if os.path.exists(path):
                    service = Service(path)
                    print(f"ğŸ”§ ChromeDriver ê²½ë¡œ ë°œê²¬: {path}")
                    break
            
            if service:
                driver = webdriver.Chrome(service=service, options=chrome_options)
                print(f"âœ… Chrome ë“œë¼ì´ë²„ ìƒì„± ì„±ê³µ (ëª…ì‹œì  ê²½ë¡œ)")
            else:
                # fallback to system path
                driver = webdriver.Chrome(options=chrome_options)
                print("âœ… Chrome ë“œë¼ì´ë²„ ìƒì„± ì„±ê³µ (ì‹œìŠ¤í…œ ê²½ë¡œ)")
            
        except Exception as e:
            print(f"âŒ Chrome ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
        
        if driver:
            # íƒ€ì„ì•„ì›ƒ ë° ê¸°ë³¸ ì„¤ì •
            driver.implicitly_wait(10)
            driver.set_page_load_timeout(30)
            
            # ì„¸ì…˜ ì •ë³´ ì €ì¥ (ì •ë¦¬ìš©)
            driver._temp_dir = temp_dir
            driver._debug_port = debug_port
            
            # ìë™í™” ê°ì§€ ë°©ì§€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            print("âœ… Chrome ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
            return driver
        else:
            return None
                
    except Exception as e:
        print(f"âŒ Chrome ë“œë¼ì´ë²„ ì„¤ì • ì¤‘ ì „ì²´ ì˜¤ë¥˜: {e}")
        return None

def get_webpage_with_selenium(url, attempt=1, max_attempts=5):
    """Seleniumì„ ì‚¬ìš©í•œ ë™ì  ì›¹í˜ì´ì§€ HTML ê°€ì ¸ì˜¤ê¸° (ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)"""
    driver = None
    
    for current_attempt in range(attempt, max_attempts + 1):
        try:
            print(f"ğŸ”„ Selenium WebDriver ì‹œì‘... (ì‹œë„ {current_attempt}/{max_attempts})")
            
            # ì´ì „ ì‹œë„ì—ì„œ ì‹¤íŒ¨í•œ ê²½ìš° Chrome í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
            if current_attempt > 1:
                try:
                    subprocess.run(['pkill', '-f', 'chrome'], capture_output=True, timeout=5)
                    subprocess.run(['pkill', '-f', 'chromedriver'], capture_output=True, timeout=5)
                    time.sleep(3)
                    print("ğŸ§¹ ì´ì „ Chrome í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì™„ë£Œ")
                except:
                    pass
            
            driver = setup_chrome_driver_ubuntu()
            if not driver:
                if current_attempt < max_attempts:
                    print(f"âŒ Chrome ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨ (ì‹œë„ {current_attempt}/{max_attempts}) - ì¬ì‹œë„")
                    continue
                else:
                    print(f"âŒ Chrome ë“œë¼ì´ë²„ ì„¤ì • ìµœì¢… ì‹¤íŒ¨")
                    return None
            
            print(f"ğŸ“„ í˜ì´ì§€ ë¡œë”© ì¤‘: {url} (ì‹œë„ {current_attempt}/{max_attempts})")
            driver.get(url)
            
            # í˜ì´ì§€ ê¸°ë³¸ ë¡œë“œ ëŒ€ê¸°
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            print("âœ… ê¸°ë³¸ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
            
            # ë™ì  ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸°
            time.sleep(5)
            
            # í•µì‹¬ ìš”ì†Œë“¤ ëŒ€ê¸°
            for element_id in ["contentBody", "conScroll"]:
                try:
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.ID, element_id))
                    )
                    print(f"âœ… {element_id} ìš”ì†Œ ë¡œë“œ í™•ì¸")
                except:
                    print(f"âš ï¸ {element_id} ìš”ì†Œ ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ")
            
            # pgroup í´ë˜ìŠ¤ ìš”ì†Œë“¤ ëŒ€ê¸°
            try:
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CLASS_NAME, "pgroup"))
                )
                print("âœ… pgroup ìš”ì†Œ ë¡œë“œ í™•ì¸")
            except:
                print("âš ï¸ pgroup ìš”ì†Œ ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ")
            
            time.sleep(3)
            
            html_content = driver.page_source
            
            # ì„±ê³µì ìœ¼ë¡œ HTML ë‚´ìš©ì„ ì–»ì—ˆëŠ”ì§€ ê²€ì¦
            if html_content and len(html_content) > 1000:  # ìµœì†Œ ê¸¸ì´ í™•ì¸
                print(f"âœ… Seleniumìœ¼ë¡œ ì›¹í˜ì´ì§€ ìš”ì²­ ì„±ê³µ: {len(html_content)}ì (ì‹œë„ {current_attempt}/{max_attempts})")
                return html_content
            else:
                raise Exception(f"HTML ë‚´ìš©ì´ ë¶€ì¡±í•¨: {len(html_content) if html_content else 0}ì")
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ Selenium ì›¹í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {current_attempt}/{max_attempts}): {error_msg}")
            
            if current_attempt < max_attempts:
                wait_time = current_attempt * 2  # ì¬ì‹œë„ ê°„ê²© ì¦ê°€
                print(f"â° {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(wait_time)
            else:
                print(f"ğŸ’¥ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ({max_attempts}íšŒ)")
                return None
                
        finally:
            # ê° ì‹œë„ë§ˆë‹¤ ë“œë¼ì´ë²„ ì •ë¦¬
            if driver:
                try:
                    # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë³´ ì €ì¥
                    temp_dir = getattr(driver, '_temp_dir', None)
                    driver.quit()
                    print(f"ğŸ”š ë¸Œë¼ìš°ì € ì¢…ë£Œ (ì‹œë„ {current_attempt})")
                    
                    # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
                    if temp_dir:
                        try:
                            import shutil
                            shutil.rmtree(temp_dir)
                            print(f"ğŸ§¹ ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬: {temp_dir}")
                        except:
                            pass
                except:
                    pass
                driver = None
    
    return None

def crawl_anticorruption_law_with_retry(max_attempts=5):
    """ì²­íƒê¸ˆì§€ë²• í¬ë¡¤ë§ í•¨ìˆ˜ (ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)"""
    iframe_url = "https://www.law.go.kr/LSW//lsInfoP.do?lsiSeq=268655&chrClsCd=010202&urlMode=lsInfoP&efYd=20250121&ancYnChk=0"
    
    for attempt in range(1, max_attempts + 1):
        scraped_data = {}
        
        try:
            print(f"\nğŸ”„ ì²­íƒê¸ˆì§€ë²• í¬ë¡¤ë§ ì‹œì‘ (ì‹œë„ {attempt}/{max_attempts})")
            print(f"ğŸ“„ iframe í˜ì´ì§€ ì ‘ì†: {iframe_url}")
            
            # Seleniumìœ¼ë¡œ ë™ì  ì½˜í…ì¸  ë¡œë”© (ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)
            html_content = get_webpage_with_selenium(iframe_url, attempt=1, max_attempts=3)
            if not html_content:
                raise Exception("iframe í˜ì´ì§€ HTMLì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            soup = BeautifulSoup(html_content, 'html.parser')
            print("âœ… HTML íŒŒì‹± ì™„ë£Œ")
            
            # ë²•ëª… ìˆ˜ì§‘
            try:
                con_top = soup.find('div', id='conTop')
                if con_top and con_top.find('h2'):
                    law_name = con_top.find('h2').get_text(strip=True)
                    scraped_data['ë²•ëª…'] = law_name
                    print(f"âœ… ë²•ëª… ìˆ˜ì§‘ ì™„ë£Œ: {law_name}")
                else:
                    scraped_data['ë²•ëª…'] = "ë²•ëª… ìˆ˜ì§‘ ì‹¤íŒ¨"
            except Exception as e:
                scraped_data['ë²•ëª…'] = f"ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
            
            # ì‹œí–‰ ë²•ë¥  ì •ë³´ ìˆ˜ì§‘
            try:
                con_top = soup.find('div', id='conTop')
                if con_top:
                    div_elements = con_top.find_all('div', recursive=False)
                    if div_elements:
                        law_info = div_elements[0].get_text(strip=True)
                        scraped_data['ì‹œí–‰_ë²•ë¥ _ì •ë³´'] = law_info
                        print(f"âœ… ì‹œí–‰ ë²•ë¥  ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {law_info[:100]}...")
                    else:
                        scraped_data['ì‹œí–‰_ë²•ë¥ _ì •ë³´'] = "ì‹œí–‰ ë²•ë¥  ì •ë³´ ì—†ìŒ"
                else:
                    scraped_data['ì‹œí–‰_ë²•ë¥ _ì •ë³´'] = "conTop div ì—†ìŒ"
            except Exception as e:
                scraped_data['ì‹œí–‰_ë²•ë¥ _ì •ë³´'] = f"ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
            
            # pgroup í…ìŠ¤íŠ¸ ì¶”ì¶œ (í•µì‹¬ ê¸°ëŠ¥)
            try:
                # DOM êµ¬ì¡° íƒìƒ‰: bodyId â†’ searchForm â†’ container â†’ center â†’ bodyContentTOP â†’ viewwrapCenter â†’ bodyContent â†’ contentBody â†’ sideCenter â†’ conScroll
                path_elements = [
                    'bodyId', 'searchForm', 'container', 'center', 'bodyContentTOP', 
                    'viewwrapCenter', 'bodyContent', 'contentBody', 'sideCenter', 'conScroll'
                ]
                
                current_element = soup
                for element_id in path_elements:
                    current_element = current_element.find(id=element_id)
                    if current_element:
                        print(f"âœ“ {element_id} ë°œê²¬")
                    else:
                        print(f"âœ— {element_id} ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        break
                
                # conScrollì—ì„œ pgroup ìš”ì†Œë“¤ ì¶”ì¶œ
                if current_element:  # conScrollì´ ë°œê²¬ëœ ê²½ìš°
                    all_pgroups = current_element.find_all('div', class_='pgroup')
                    if all_pgroups:
                        print(f"âœ“ pgroup í´ë˜ìŠ¤ div {len(all_pgroups)}ê°œ ë°œê²¬")
                        
                        pgroup_texts = []
                        for i, pgroup in enumerate(all_pgroups):
                            text = pgroup.get_text(strip=True)
                            if text:
                                pgroup_texts.append(text)
                                print(f"  - pgroup {i+1}: {len(text)}ì")
                        
                        scraped_data['pgroup_í…ìŠ¤íŠ¸'] = pgroup_texts
                        scraped_data['pgroup_ê°œìˆ˜'] = len(pgroup_texts)
                        print(f"âœ… ì´ {len(pgroup_texts)}ê°œ pgroup í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ")
                        
                        # ì„±ê³µ ì¡°ê±´ í™•ì¸
                        if len(pgroup_texts) > 0:
                            # í¬ë¡¤ë§ ë©”íƒ€ë°ì´í„°
                            scraped_data['í¬ë¡¤ë§_ì‹œê°„'] = datetime.now().isoformat()
                            scraped_data['ì†ŒìŠ¤_URL'] = iframe_url
                            scraped_data['í¬ë¡¤ë§_ìƒíƒœ'] = "ì„±ê³µ"
                            scraped_data['ì‹œë„_íšŸìˆ˜'] = attempt
                            
                            print(f"ğŸ‰ ì²­íƒê¸ˆì§€ë²• í¬ë¡¤ë§ ì„±ê³µ! (ì‹œë„ {attempt}/{max_attempts})")
                            return scraped_data
                        else:
                            raise Exception("pgroup í…ìŠ¤íŠ¸ê°€ ìˆ˜ì§‘ë˜ì§€ ì•ŠìŒ")
                    else:
                        raise Exception("pgroup í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                else:
                    raise Exception("DOM êµ¬ì¡° íƒìƒ‰ ì‹¤íŒ¨ - conScroll ìš”ì†Œ ì—†ìŒ")
                    
            except Exception as e:
                print(f"âŒ pgroup í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                raise e
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨ (ì‹œë„ {attempt}/{max_attempts}): {error_msg}")
            
            if attempt < max_attempts:
                wait_time = attempt * 3  # ì¬ì‹œë„ ê°„ê²© ì¦ê°€
                print(f"â° {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(wait_time)
            else:
                print(f"ğŸ’¥ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ({max_attempts}íšŒ)")
                # ìµœì¢… ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ì •ë³´ ë°˜í™˜
                scraped_data = {
                    'ë²•ëª…': "í¬ë¡¤ë§ ì‹¤íŒ¨",
                    'ì‹œí–‰_ë²•ë¥ _ì •ë³´': "í¬ë¡¤ë§ ì‹¤íŒ¨", 
                    'í¬ë¡¤ë§_ì‹œê°„': datetime.now().isoformat(),
                    'ì†ŒìŠ¤_URL': iframe_url,
                    'í¬ë¡¤ë§_ìƒíƒœ': "ì‹¤íŒ¨",
                    'ì‹œë„_íšŸìˆ˜': max_attempts,
                    'ì˜¤ë¥˜_ë©”ì‹œì§€': error_msg
                }
                return scraped_data
    
    # ì—¬ê¸°ê¹Œì§€ ì˜¤ë©´ ì•ˆë¨, í•˜ì§€ë§Œ ì•ˆì „ì¥ì¹˜
    return {
        'í¬ë¡¤ë§_ìƒíƒœ': "ì‹¤íŒ¨",
        'ì˜¤ë¥˜_ë©”ì‹œì§€': "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜"
    }


def save_to_json(data, filename=None):
    """JSON íŒŒì¼ë¡œ ì €ì¥"""
    if filename is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'anticorruption_law_{timestamp}.json'
    
    # crawler_result ë””ë ‰í† ë¦¬ì— ì €ì¥ - Docker ë³¼ë¥¨ ë§ˆìš´íŠ¸ëœ ê²½ë¡œ ì‚¬ìš©
    result_dir = '/home/son/SKN12-FINAL-AIRFLOW/crawler_result'
    
    os.makedirs(result_dir, exist_ok=True)
    filepath = os.path.join(result_dir, filename)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return filepath

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)"""
    print("ğŸ”„ ì²­íƒê¸ˆì§€ë²• í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("=" * 60)
    
    try:
        # ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ì´ í¬í•¨ëœ í¬ë¡¤ë§ ì‹¤í–‰
        data = crawl_anticorruption_law_with_retry(max_attempts=5)
        
        if data and data.get('í¬ë¡¤ë§_ìƒíƒœ') == 'ì„±ê³µ':
            filepath = save_to_json(data)
            print("\nğŸ‰ í¬ë¡¤ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
            
            # ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
            print("\n" + "=" * 60)
            print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
            print("=" * 60)
            print(f"ğŸ“„ ë²•ëª…: {data.get('ë²•ëª…', 'N/A')}")
            print(f"ğŸ“… ì‹œí–‰ ì •ë³´: {data.get('ì‹œí–‰_ë²•ë¥ _ì •ë³´', 'N/A')[:100]}...")
            print(f"ğŸ“ pgroup ê°œìˆ˜: {data.get('pgroup_ê°œìˆ˜', 0)}ê°œ")
            print(f"ğŸ”„ ì„±ê³µí•œ ì‹œë„: {data.get('ì‹œë„_íšŸìˆ˜', 'N/A')}ë²ˆì§¸")
            print(f"â° í¬ë¡¤ë§ ì‹œê°„: {data.get('í¬ë¡¤ë§_ì‹œê°„', 'N/A')}")
                
        else:
            print(f"\nğŸ’¥ í¬ë¡¤ë§ ìµœì¢… ì‹¤íŒ¨")
            print(f"âŒ ì˜¤ë¥˜: {data.get('ì˜¤ë¥˜_ë©”ì‹œì§€', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            print(f"ğŸ”„ ì´ ì‹œë„ íšŸìˆ˜: {data.get('ì‹œë„_íšŸìˆ˜', 'N/A')}íšŒ")
            
            # ì‹¤íŒ¨í•œ ë°ì´í„°ë„ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            failed_filename = f'anticorruption_law_failed_{timestamp}.json'
            filepath = save_to_json(data, failed_filename)
            print(f"ğŸ’¾ ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥: {filepath}")
    
    except Exception as unexpected_error:
        print(f"\nğŸ’¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(unexpected_error)}")
        
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ë„ ê¸°ë¡
        error_data = {
            'í¬ë¡¤ë§_ìƒíƒœ': "ì˜ˆìƒì¹˜_ëª»í•œ_ì˜¤ë¥˜",
            'ì˜¤ë¥˜_ë©”ì‹œì§€': str(unexpected_error),
            'í¬ë¡¤ë§_ì‹œê°„': datetime.now().isoformat()
        }
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        error_filename = f'anticorruption_law_unexpected_error_{timestamp}.json'
        save_to_json(error_data, error_filename)
    
    finally:
        # Chrome í”„ë¡œì„¸ìŠ¤ ìµœì¢… ì •ë¦¬
        try:
            subprocess.run(['pkill', '-f', 'chrome'], capture_output=True, timeout=5)
            subprocess.run(['pkill', '-f', 'chromedriver'], capture_output=True, timeout=5)
            print("\nğŸ§¹ Chrome í”„ë¡œì„¸ìŠ¤ ìµœì¢… ì •ë¦¬ ì™„ë£Œ")
        except:
            pass
        
        print("\n" + "=" * 60)
        print("ğŸ ì²­íƒê¸ˆì§€ë²• í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
        print("=" * 60)

if __name__ == "__main__":
    main()