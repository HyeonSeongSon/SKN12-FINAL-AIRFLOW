#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ ë‰´ìŠ¤ìŠ¤íƒ ë“œ í¬ë¡¤ë§ Airflow DAG
ë§¤ì¼ 09:00, 13:00ì— KBS/MBC/SBS ë‰´ìŠ¤ ìˆ˜ì§‘ ë° AI ìš”ì•½ ìƒì„±
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.email import EmailOperator
from datetime import datetime, timedelta
import os
import sys
import subprocess
import logging

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# ê¸°ë³¸ DAG ì„¤ì •
default_args = {
    'owner': 'news-team',
    'depends_on_past': False,
    'start_date': datetime(2025, 7, 31),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=10),
    'catchup': True,
    'email': ['inexorable17@gmail.com']  # ì‹¤ì œ ì´ë©”ì¼ ì£¼ì†Œë¡œ ë³€ê²½
}

# DAG ì •ì˜
dag = DAG(
    'naver_news_crawler',
    default_args=default_args,
    description='ë„¤ì´ë²„ ë‰´ìŠ¤ìŠ¤íƒ ë“œ KBS/MBC/SBS í¬ë¡¤ë§ ë° AI ìš”ì•½',
    schedule='0 9,13 * * *',  # ë§¤ì¼ 09:00, 13:00 (UTC ê¸°ì¤€)
    max_active_runs=1,
    tags=['news', 'crawler', 'ai-summary']
)

def run_news_crawler():
    """ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # í¬ë¡¤ëŸ¬ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ
        crawler_script = os.path.join(os.path.dirname(current_dir), 'func', 'newsstand_crawler.py')
        
        # í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸
        if not os.getenv('OPENAI_API_KEY'):
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        logging.info(f"ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹œì‘: {crawler_script}")
        
        # Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        result = subprocess.run(
            [sys.executable, crawler_script],
            capture_output=True,
            text=True,
            timeout=1800,  # 30ë¶„ íƒ€ì„ì•„ì›ƒ
            cwd=os.path.join(os.path.dirname(current_dir), 'func')
        )
        
        # ì‹¤í–‰ ê²°ê³¼ ë¡œê¹…
        if result.returncode == 0:
            logging.info("âœ… ë‰´ìŠ¤ í¬ë¡¤ë§ ì„±ê³µ")
            logging.info(f"ì¶œë ¥:\n{result.stdout}")
            
            # ìƒì„±ëœ íŒŒì¼ í™•ì¸
            import glob
            func_dir = os.path.join(os.path.dirname(current_dir), 'func')
            json_files = glob.glob(os.path.join(func_dir, 'newsstand_*.json'))
            if json_files:
                latest_file = max(json_files, key=os.path.getctime)
                logging.info(f"ìƒì„±ëœ íŒŒì¼: {latest_file}")
                return {'status': 'success', 'file': latest_file, 'output': result.stdout}
            else:
                logging.warning("JSON íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return {'status': 'warning', 'message': 'JSON íŒŒì¼ ì—†ìŒ', 'output': result.stdout}
        else:
            logging.error(f"âŒ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨ (exit code: {result.returncode})")
            logging.error(f"ì—ëŸ¬:\n{result.stderr}")
            raise RuntimeError(f"í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
            
    except subprocess.TimeoutExpired:
        logging.error("âŒ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ íƒ€ì„ì•„ì›ƒ (30ë¶„)")
        raise RuntimeError("í¬ë¡¤ëŸ¬ ì‹¤í–‰ íƒ€ì„ì•„ì›ƒ")
    except Exception as e:
        logging.error(f"âŒ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise

def check_and_notify(**context):
    """í¬ë¡¤ë§ ê²°ê³¼ í™•ì¸ ë° ì•Œë¦¼"""
    try:
        # ì´ì „ íƒœìŠ¤í¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        task_result = context['task_instance'].xcom_pull(task_ids='run_crawler')
        
        if task_result and task_result.get('status') == 'success':
            logging.info("âœ… í¬ë¡¤ë§ ì„±ê³µ - ì•Œë¦¼ ì „ì†¡")
            
            # ê²°ê³¼ íŒŒì¼ ì •ë³´
            result_file = task_result.get('file', 'Unknown')
            file_name = os.path.basename(result_file) if result_file != 'Unknown' else 'Unknown'
            
            # ì„±ê³µ ë©”ì‹œì§€ ë°˜í™˜ (EmailOperatorì—ì„œ ì‚¬ìš©)
            return {
                'subject': f'[SUCCESS] ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì™„ë£Œ - {datetime.now().strftime("%Y-%m-%d %H:%M")}',
                'content': f'''
ğŸ‰ ë„¤ì´ë²„ ë‰´ìŠ¤ìŠ¤íƒ ë“œ í¬ë¡¤ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ“Š ì‹¤í–‰ ì •ë³´:
- ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- ìƒì„± íŒŒì¼: {file_name}
- ëŒ€ìƒ ì–¸ë¡ ì‚¬: KBS, MBC, SBS

ğŸ“ íŒŒì¼ ìœ„ì¹˜: {result_file}

âœ… ëª¨ë“  ë‰´ìŠ¤ì— ëŒ€í•œ AI ìš”ì•½ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
                '''
            }
        else:
            logging.warning("âš ï¸ í¬ë¡¤ë§ ë¶€ë¶„ ì„±ê³µ ë˜ëŠ” ì‹¤íŒ¨")
            return {
                'subject': f'[WARNING] ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì´ìŠˆ - {datetime.now().strftime("%Y-%m-%d %H:%M")}',
                'content': f'''
âš ï¸ ë„¤ì´ë²„ ë‰´ìŠ¤ìŠ¤íƒ ë“œ í¬ë¡¤ë§ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ğŸ“Š ì‹¤í–‰ ì •ë³´:
- ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- ìƒíƒœ: {task_result.get('status', 'Unknown') if task_result else 'Failed'}
- ë©”ì‹œì§€: {task_result.get('message', 'No message') if task_result else 'Task failed'}

ğŸ” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œë¥¼ ì§„ë‹¨í•´ì£¼ì„¸ìš”.
                '''
            }
            
    except Exception as e:
        logging.error(f"âŒ ì•Œë¦¼ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            'subject': f'[ERROR] ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜ - {datetime.now().strftime("%Y-%m-%d %H:%M")}',
            'content': f'''
âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ìŠ¤íƒ ë“œ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ğŸ“Š ì˜¤ë¥˜ ì •ë³´:
- ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- ì˜¤ë¥˜: {str(e)}

ğŸ” Airflow ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œë¥¼ ì§„ë‹¨í•´ì£¼ì„¸ìš”.
            '''
        }

def send_notification_email(**context):
    """ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡"""
    try:
        # ì´ì „ íƒœìŠ¤í¬ì—ì„œ ì¤€ë¹„ëœ ì•Œë¦¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        notification_data = context['task_instance'].xcom_pull(task_ids='check_result')
        
        if notification_data:
            # EmailOperator ë™ì  ìƒì„± ë° ì‹¤í–‰
            email_task = EmailOperator(
                task_id='send_email_dynamic',
                to=['inexorable17@gmail.com'],
                subject=notification_data['subject'],
                html_content=notification_data['content'].replace('\n', '<br>'),
                dag=dag
            )
            
            # ì´ë©”ì¼ ì „ì†¡ ì‹¤í–‰
            email_task.execute(context)
            logging.info("âœ… ì•Œë¦¼ ì´ë©”ì¼ ì „ì†¡ ì™„ë£Œ")
        else:
            logging.warning("âš ï¸ ì•Œë¦¼ ë°ì´í„°ê°€ ì—†ì–´ ì´ë©”ì¼ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        logging.error(f"âŒ ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
        # ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨ëŠ” ì „ì²´ DAG ì‹¤íŒ¨ë¡œ ì´ì–´ì§€ì§€ ì•Šë„ë¡ í•¨
        pass

# Task ì •ì˜
crawler_task = PythonOperator(
    task_id='run_crawler',
    python_callable=run_news_crawler,
    dag=dag,
    pool='crawler_pool',  # ë¦¬ì†ŒìŠ¤ í’€ ì‚¬ìš© (ì„ íƒì‚¬í•­)
    execution_timeout=timedelta(minutes=30)
)

check_task = PythonOperator(
    task_id='check_result',
    python_callable=check_and_notify,
    dag=dag,
)

email_task = PythonOperator(
    task_id='send_notification',
    python_callable=send_notification_email,
    dag=dag,
    trigger_rule='all_done'  # ì´ì „ íƒœìŠ¤í¬ê°€ ì„±ê³µ/ì‹¤íŒ¨ ê´€ê³„ì—†ì´ ì‹¤í–‰
)

# Task ì˜ì¡´ì„± ì„¤ì •
crawler_task >> check_task >> email_task

# DAG ë¬¸ì„œí™”
dag.doc_md = """
# ë„¤ì´ë²„ ë‰´ìŠ¤ìŠ¤íƒ ë“œ í¬ë¡¤ë§ DAG

## ê°œìš”
ì´ DAGëŠ” ë„¤ì´ë²„ ë‰´ìŠ¤ìŠ¤íƒ ë“œì—ì„œ KBS, MBC, SBS ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  AI ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.

## ì‹¤í–‰ ì¼ì •
- **ë§¤ì¼ 09:00, 13:00** (UTC ê¸°ì¤€)
- í•œ ë²ˆì— í•˜ë‚˜ì˜ DAG ì¸ìŠ¤í„´ìŠ¤ë§Œ ì‹¤í–‰

## ì£¼ìš” ê¸°ëŠ¥
1. **ë‰´ìŠ¤ ìˆ˜ì§‘**: iframe ê¸°ë°˜ìœ¼ë¡œ KBS/MBC/SBS ë‰´ìŠ¤ í¬ë¡¤ë§
2. **AI ìš”ì•½**: OpenAI GPTë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ìš”ì•½ ìƒì„±
3. **ê²°ê³¼ ì €ì¥**: JSON í˜•íƒœë¡œ íŒŒì¼ ì €ì¥
4. **ì•Œë¦¼**: ì‹¤í–‰ ê²°ê³¼ë¥¼ ì´ë©”ì¼ë¡œ í†µì§€

## í™˜ê²½ ì„¤ì •
- `OPENAI_API_KEY`: OpenAI API í‚¤ (í•„ìˆ˜)
- Chrome/ChromeDriver ì„¤ì¹˜ í•„ìš”
- ì´ë©”ì¼ SMTP ì„¤ì • í•„ìš”

## ì‚°ì¶œë¬¼
- `newsstand_YYYYMMDD_HHMMSS.json`: í¬ë¡¤ë§ ê²°ê³¼ íŒŒì¼
"""