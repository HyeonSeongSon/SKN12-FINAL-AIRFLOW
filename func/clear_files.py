import os
import re
from datetime import datetime
from collections import defaultdict


def _clear_files_by_patterns(patterns, description):
    """
    ì§€ì •ëœ íŒ¨í„´ë“¤ì˜ íŒŒì¼ì´ 3ê°œ ì´ˆê³¼í•˜ë©´ ìµœê·¼ 3ê°œë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì‚­ì œ
    
    Args:
        patterns: ëŒ€ìƒ íŒŒì¼ íŒ¨í„´ë“¤ (ë¦¬ìŠ¤íŠ¸)
        description: ë¡œê·¸ì— í‘œì‹œí•  ì„¤ëª…
    """
    crawler_result_path = '/home/son/SKN12-FINAL-AIRFLOW/crawler_result'
    
    try:
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(crawler_result_path):
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {crawler_result_path}")
            return
        
        # íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        all_files = os.listdir(crawler_result_path)
        print(f"ğŸ“ {description} - ì „ì²´ íŒŒì¼ ê°œìˆ˜: {len(all_files)}")
        
        # ê° íŒ¨í„´ë³„ë¡œ íŒŒì¼ ê·¸ë£¹í™”
        file_groups = defaultdict(list)
        
        for filename in all_files:
            # JSON íŒŒì¼ë§Œ ì²˜ë¦¬
            if not filename.endswith('.json'):
                continue
                
            # ëŒ€ìƒ íŒ¨í„´ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ì¸ì§€ í™•ì¸
            for pattern in patterns:
                if filename.startswith(pattern):
                    # íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ
                    file_path = os.path.join(crawler_result_path, filename)
                    
                    # íŒŒì¼ ìƒì„± ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
                    creation_time = os.path.getctime(file_path)
                    
                    # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì‹œë„
                    date_match = re.search(r'(\d{8})', filename)
                    if date_match:
                        try:
                            # íŒŒì¼ëª…ì˜ ë‚ ì§œë¥¼ ìš°ì„  ì‚¬ìš©
                            date_str = date_match.group(1)
                            file_date = datetime.strptime(date_str, '%Y%m%d')
                            sort_key = file_date.timestamp()
                        except:
                            # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ íŒŒì¼ ìƒì„± ì‹œê°„ ì‚¬ìš©
                            sort_key = creation_time
                    else:
                        # ë‚ ì§œ ì •ë³´ê°€ ì—†ìœ¼ë©´ íŒŒì¼ ìƒì„± ì‹œê°„ ì‚¬ìš©
                        sort_key = creation_time
                    
                    file_groups[pattern].append({
                        'filename': filename,
                        'path': file_path,
                        'sort_key': sort_key,
                        'creation_time': creation_time
                    })
                    break
        
        # ê° ê·¸ë£¹ë³„ë¡œ íŒŒì¼ ì •ë¦¬
        total_deleted = 0
        
        for pattern, files in file_groups.items():
            if len(files) <= 3:
                print(f"âœ… {pattern}: {len(files)}ê°œ íŒŒì¼ - ì •ë¦¬ ë¶ˆí•„ìš”")
                continue
            
            print(f"ğŸ” {pattern}: {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
            
            # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬ (sort_key ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
            files.sort(key=lambda x: x['sort_key'], reverse=True)
            
            # ìµœì‹  3ê°œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ íŒŒì¼ë“¤
            files_to_delete = files[3:]
            
            print(f"ğŸ“‹ ë³´ì¡´í•  íŒŒì¼ (ìµœì‹  3ê°œ):")
            for i, file_info in enumerate(files[:3]):
                date_str = datetime.fromtimestamp(file_info['sort_key']).strftime('%Y-%m-%d %H:%M:%S')
                print(f"  {i+1}. {file_info['filename']} ({date_str})")
            
            print(f"ğŸ—‘ï¸  ì‚­ì œí•  íŒŒì¼ ({len(files_to_delete)}ê°œ):")
            for file_info in files_to_delete:
                try:
                    os.remove(file_info['path'])
                    date_str = datetime.fromtimestamp(file_info['sort_key']).strftime('%Y-%m-%d %H:%M:%S')
                    print(f"  âœ… ì‚­ì œ: {file_info['filename']} ({date_str})")
                    total_deleted += 1
                except Exception as e:
                    print(f"  âŒ ì‚­ì œ ì‹¤íŒ¨: {file_info['filename']} - {str(e)}")
            
            print()
        
        print(f"ğŸ‰ {description} ì •ë¦¬ ì™„ë£Œ! ì´ {total_deleted}ê°œ íŒŒì¼ ì‚­ì œë¨")
        
    except Exception as e:
        print(f"âŒ {description} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def clear_medical_news_files():
    """
    ì˜ë£Œ ë‰´ìŠ¤ ê´€ë ¨ íŒŒì¼ ì •ë¦¬
    ëŒ€ìƒ: medical_top_trending_news_, medical_recent_news_
    """
    patterns = ['medical_top_trending_news_', 'medical_recent_news_']
    _clear_files_by_patterns(patterns, "ì˜ë£Œ ë‰´ìŠ¤ íŒŒì¼")


def clear_newsstand_files():
    """
    ë‰´ìŠ¤ìŠ¤íƒ ë“œ ê´€ë ¨ íŒŒì¼ ì •ë¦¬
    ëŒ€ìƒ: newsstand_iframe_
    """
    patterns = ['newsstand_iframe_']
    _clear_files_by_patterns(patterns, "ë‰´ìŠ¤ìŠ¤íƒ ë“œ íŒŒì¼")


def clear_excel_files(file_type):
    """
    ì§€ì •ëœ íƒ€ì…ì˜ íŒŒì¼ì„ /home/son/SKN12-FINAL-AIRFLOW/crawler_result ê²½ë¡œì—ì„œ ì‚­ì œ
    
    Args:
        file_type (str): ì‚­ì œí•  íŒŒì¼ íƒ€ì…
            - 'law': anticorruption_law_processed_*.xlsx ì‚­ì œ
            - 'medical': medical_news_unique_*.xlsx ì‚­ì œ  
            - 'newsstand': newsstand_iframe_unique_*.xlsx ì‚­ì œ
            - 'hira': hira_data*.xlsx ì‚­ì œ
            - 'news_report': pharmaceutical_strategy_report_*.md ì‚­ì œ
    """
    crawler_result_path = '/home/son/SKN12-FINAL-AIRFLOW/crawler_result'
    
    # íƒ€ì…ë³„ íŒŒì¼ íŒ¨í„´ ì •ì˜
    patterns = {
        'law': {'pattern': 'anticorruption_law_processed_', 'extensions': ['.xlsx', '.xls']},
        'medical': {'pattern': 'medical_news_unique_', 'extensions': ['.xlsx', '.xls']},
        'newsstand': {'pattern': 'newsstand_iframe_unique_', 'extensions': ['.xlsx', '.xls']},
        'hira': {'pattern': 'hira_data', 'extensions': ['.xlsx', '.xls']},
        'news_report': {'pattern': 'pharmaceutical_strategy_report_', 'extensions': ['.md']}
    }
    
    if file_type not in patterns:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…ì…ë‹ˆë‹¤: {file_type}")
        print(f"   ì§€ì› íƒ€ì…: {list(patterns.keys())}")
        return
    
    pattern_info = patterns[file_type]
    pattern = pattern_info['pattern']
    extensions = pattern_info['extensions']
    
    try:
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(crawler_result_path):
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {crawler_result_path}")
            return
        
        file_types_desc = "/".join(extensions)
        print(f"ğŸ” {pattern} {file_types_desc} íŒŒì¼ ê²€ìƒ‰ ì¤‘... (ê²½ë¡œ: {crawler_result_path})")
        
        # ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ í™•ì¸
        all_files = os.listdir(crawler_result_path)
        target_files = []
        
        for filename in all_files:
            # íŒ¨í„´ê³¼ í™•ì¥ìê°€ ì¼ì¹˜í•˜ëŠ” íŒŒì¼ ì°¾ê¸°
            if pattern in filename and any(filename.endswith(ext) for ext in extensions):
                target_files.append(filename)
        
        if not target_files:
            print(f"âœ… {pattern} {file_types_desc} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“‹ ë°œê²¬ëœ íŒŒì¼ ({len(target_files)}ê°œ):")
        for filename in target_files:
            file_path = os.path.join(crawler_result_path, filename)
            file_size = os.path.getsize(file_path)
            creation_time = datetime.fromtimestamp(os.path.getctime(file_path))
            print(f"  - {filename} ({file_size:,} bytes, {creation_time.strftime('%Y-%m-%d %H:%M:%S')})")
        
        # íŒŒì¼ ì‚­ì œ ì‹¤í–‰
        deleted_count = 0
        for filename in target_files:
            try:
                file_path = os.path.join(crawler_result_path, filename)
                os.remove(file_path)
                print(f"  âœ… ì‚­ì œ ì™„ë£Œ: {filename}")
                deleted_count += 1
            except Exception as e:
                print(f"  âŒ ì‚­ì œ ì‹¤íŒ¨: {filename} - {str(e)}")
        
        print(f"ğŸ‰ {pattern} {file_types_desc} íŒŒì¼ ì •ë¦¬ ì™„ë£Œ! ì´ {deleted_count}ê°œ íŒŒì¼ ì‚­ì œë¨")
        
    except Exception as e:
        print(f"âŒ {pattern} íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def clear_json_files(file_type):
    """
    ì§€ì •ëœ íƒ€ì…ì˜ JSON íŒŒì¼ì„ /home/son/SKN12-FINAL-AIRFLOW/crawler_result ê²½ë¡œì—ì„œ ê´€ë¦¬
    ë™ì¼í•œ íŒ¨í„´ì˜ íŒŒì¼ì´ 5ê°œ ì´ìƒì´ë©´ ê°€ì¥ ì˜¤ë˜ëœ íŒŒì¼ì„ ì‚­ì œí•˜ì—¬ ìµœì‹  4ê°œë§Œ ìœ ì§€
    
    Args:
        file_type (str): ì‚­ì œí•  íŒŒì¼ íƒ€ì…
            - 'newsstand': newsstand_iframe_YYYYMMDD_hhmmss.json íŒŒì¼ ê´€ë¦¬
            - 'medical_recent': medical_recent_news_YYYYMMDD_hhmmss.json íŒŒì¼ ê´€ë¦¬
            - 'medical_trending': medical_top_trending_news_YYYYMMDD_hhmmss.json íŒŒì¼ ê´€ë¦¬
    """
    crawler_result_path = '/home/son/SKN12-FINAL-AIRFLOW/crawler_result'
    
    # íƒ€ì…ë³„ íŒŒì¼ íŒ¨í„´ ì •ì˜
    patterns = {
        'newsstand': 'newsstand_iframe_',
        'medical_recent': 'medical_recent_news_',
        'medical_trending': 'medical_top_trending_news_'
    }
    
    if file_type not in patterns:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…ì…ë‹ˆë‹¤: {file_type}")
        print(f"   ì§€ì› íƒ€ì…: {list(patterns.keys())}")
        return
    
    pattern = patterns[file_type]
    
    try:
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(crawler_result_path):
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {crawler_result_path}")
            return
        
        print(f"ğŸ” {pattern} JSON íŒŒì¼ ê²€ìƒ‰ ì¤‘... (ê²½ë¡œ: {crawler_result_path})")
        
        # ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ í™•ì¸
        all_files = os.listdir(crawler_result_path)
        target_files = []
        
        for filename in all_files:
            # JSON íŒŒì¼ì´ë©´ì„œ íŒ¨í„´ì— ì¼ì¹˜í•˜ëŠ” íŒŒì¼ ì°¾ê¸°
            if filename.startswith(pattern) and filename.endswith('.json'):
                file_path = os.path.join(crawler_result_path, filename)
                
                # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ ì‹œë„ (_YYYYMMDD_hhmmss íŒ¨í„´)
                date_time_match = re.search(r'_(\d{8})_(\d{6})\.json$', filename)
                if date_time_match:
                    try:
                        # íŒŒì¼ëª…ì˜ ë‚ ì§œì‹œê°„ì„ datetime ê°ì²´ë¡œ ë³€í™˜
                        date_str = date_time_match.group(1)  # YYYYMMDD
                        time_str = date_time_match.group(2)  # hhmmss
                        file_datetime = datetime.strptime(f"{date_str}_{time_str}", '%Y%m%d_%H%M%S')
                        sort_key = file_datetime.timestamp()
                    except:
                        # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ íŒŒì¼ ìƒì„± ì‹œê°„ ì‚¬ìš©
                        sort_key = os.path.getctime(file_path)
                else:
                    # íŒ¨í„´ì— ë§ì§€ ì•Šìœ¼ë©´ íŒŒì¼ ìƒì„± ì‹œê°„ ì‚¬ìš©
                    sort_key = os.path.getctime(file_path)
                
                target_files.append({
                    'filename': filename,
                    'path': file_path,
                    'sort_key': sort_key
                })
        
        if not target_files:
            print(f"âœ… {pattern} JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“‹ ë°œê²¬ëœ íŒŒì¼ ({len(target_files)}ê°œ):")
        
        # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬ (sort_key ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
        target_files.sort(key=lambda x: x['sort_key'], reverse=True)
        
        # íŒŒì¼ ëª©ë¡ ì¶œë ¥
        for i, file_info in enumerate(target_files):
            file_size = os.path.getsize(file_info['path'])
            date_str = datetime.fromtimestamp(file_info['sort_key']).strftime('%Y-%m-%d %H:%M:%S')
            status = "ğŸ“Œ ë³´ì¡´" if i < 4 else "ğŸ—‘ï¸ ì‚­ì œ ëŒ€ìƒ"
            print(f"  {i+1}. {file_info['filename']} ({file_size:,} bytes, {date_str}) - {status}")
        
        # 5ê°œ ì´ìƒì´ë©´ ê°€ì¥ ì˜¤ë˜ëœ íŒŒì¼ë“¤ ì‚­ì œ
        if len(target_files) >= 5:
            files_to_delete = target_files[4:]  # 5ë²ˆì§¸ë¶€í„° ëê¹Œì§€ (ê°€ì¥ ì˜¤ë˜ëœ íŒŒì¼ë“¤)
            
            print(f"\nğŸ—‘ï¸ ì‚­ì œí•  íŒŒì¼ ({len(files_to_delete)}ê°œ):")
            deleted_count = 0
            
            for file_info in files_to_delete:
                try:
                    os.remove(file_info['path'])
                    date_str = datetime.fromtimestamp(file_info['sort_key']).strftime('%Y-%m-%d %H:%M:%S')
                    print(f"  âœ… ì‚­ì œ ì™„ë£Œ: {file_info['filename']} ({date_str})")
                    deleted_count += 1
                except Exception as e:
                    print(f"  âŒ ì‚­ì œ ì‹¤íŒ¨: {file_info['filename']} - {str(e)}")
            
            print(f"\nğŸ‰ {pattern} JSON íŒŒì¼ ì •ë¦¬ ì™„ë£Œ! ì´ {deleted_count}ê°œ íŒŒì¼ ì‚­ì œë¨")
            print(f"ğŸ“Œ ìµœì‹  {len(target_files) - deleted_count}ê°œ íŒŒì¼ ë³´ì¡´ë¨")
        else:
            print(f"âœ… {pattern} JSON íŒŒì¼ì´ {len(target_files)}ê°œë¡œ ì •ë¦¬ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (5ê°œ ë¯¸ë§Œ)")
        
    except Exception as e:
        print(f"âŒ {pattern} JSON íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def clear_all_files():
    """
    ëª¨ë“  ëŒ€ìƒ íŒŒì¼ ì •ë¦¬
    """
    print("ğŸ§¹ ì „ì²´ íŒŒì¼ ì •ë¦¬ ì‹œì‘")
    print("=" * 50)
    clear_medical_news_files()
    print()
    clear_newsstand_files()


def _get_file_status_by_patterns(patterns, description):
    """
    ì§€ì •ëœ íŒ¨í„´ë“¤ì˜ í˜„ì¬ íŒŒì¼ ìƒíƒœ í™•ì¸
    
    Args:
        patterns: ëŒ€ìƒ íŒŒì¼ íŒ¨í„´ë“¤ (ë¦¬ìŠ¤íŠ¸)
        description: ë¡œê·¸ì— í‘œì‹œí•  ì„¤ëª…
    """
    crawler_result_path = '/home/son/SKN12-FINAL-AIRFLOW/crawler_result'
    
    try:
        if not os.path.exists(crawler_result_path):
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {crawler_result_path}")
            return
        
        all_files = os.listdir(crawler_result_path)
        file_groups = defaultdict(list)
        
        for filename in all_files:
            if not filename.endswith('.json'):
                continue
                
            for pattern in patterns:
                if filename.startswith(pattern):
                    file_path = os.path.join(crawler_result_path, filename)
                    creation_time = os.path.getctime(file_path)
                    
                    date_match = re.search(r'(\d{8})', filename)
                    if date_match:
                        try:
                            date_str = date_match.group(1)
                            file_date = datetime.strptime(date_str, '%Y%m%d')
                            sort_key = file_date.timestamp()
                        except:
                            sort_key = creation_time
                    else:
                        sort_key = creation_time
                    
                    file_groups[pattern].append({
                        'filename': filename,
                        'sort_key': sort_key
                    })
                    break
        
        print(f"ğŸ“Š {description} ìƒíƒœ:")
        for pattern, files in file_groups.items():
            files.sort(key=lambda x: x['sort_key'], reverse=True)
            print(f"  {pattern}: {len(files)}ê°œ")
            for i, file_info in enumerate(files):
                date_str = datetime.fromtimestamp(file_info['sort_key']).strftime('%Y-%m-%d')
                status = "âœ… ë³´ì¡´" if i < 3 else "ğŸ—‘ï¸ ì‚­ì œ ëŒ€ìƒ"
                print(f"    {file_info['filename']} ({date_str}) - {status}")
            print()
            
    except Exception as e:
        print(f"âŒ {description} ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def get_medical_news_status():
    """
    ì˜ë£Œ ë‰´ìŠ¤ íŒŒì¼ ìƒíƒœ í™•ì¸
    """
    patterns = ['medical_top_trending_news_', 'medical_recent_news_']
    _get_file_status_by_patterns(patterns, "ì˜ë£Œ ë‰´ìŠ¤ íŒŒì¼")


def get_newsstand_status():
    """
    ë‰´ìŠ¤ìŠ¤íƒ ë“œ íŒŒì¼ ìƒíƒœ í™•ì¸
    """
    patterns = ['newsstand_iframe_']
    _get_file_status_by_patterns(patterns, "ë‰´ìŠ¤ìŠ¤íƒ ë“œ íŒŒì¼")


def get_all_status():
    """
    ëª¨ë“  íŒŒì¼ ìƒíƒœ í™•ì¸
    """
    print("ğŸ“Š ì „ì²´ íŒŒì¼ ìƒíƒœ í™•ì¸")
    print("=" * 50)
    get_medical_news_status()
    get_newsstand_status()


if __name__ == "__main__":
    print("ğŸ§¹ í¬ë¡¤ëŸ¬ ê²°ê³¼ íŒŒì¼ ì •ë¦¬ ë„êµ¬")
    print("=" * 50)
    
    # í˜„ì¬ ìƒíƒœ í™•ì¸
    print("1ï¸âƒ£ í˜„ì¬ íŒŒì¼ ìƒíƒœ í™•ì¸:")
    get_all_status()
    
    print("\n2ï¸âƒ£ íŒŒì¼ ì •ë¦¬ ì‹¤í–‰:")
    clear_all_files()